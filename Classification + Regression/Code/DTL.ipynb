{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 Task 1-DTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This example will predict student result based on mid-semester exam score. On this problem we will use datasets of student exam fom kaggle (https://www.kaggle.com/shub99/student-marks). \n",
    "\n",
    "This datasets are simple and easy to implement also can relate to real-world problem. However, this datasets have less data which makes it hard to predict the accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pre-defined classes and packages.\n",
    "* heading.py includes basic methods required to run the program (created by Helen).\n",
    "* sklearn.tree for DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heading import *\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practise the Decision Tree learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To practice a decision-tree learning algorithm, we need to go through the following steps:\n",
    "* Step 1: Define the input dataset\n",
    "* Step 2: Prepare the train data and test data\n",
    "* Step 3. Train the Decison Tree learner using the training data set\n",
    "* Step 4. CTest the model's performance using the test data set\n",
    "* Step 5: Apply the model to new data examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Define the input dataset using the DataSet class from a given data file\n",
    "\n",
    "Dataset class is for modeling a dataset for a machine learning problem. It has the following atrributs/fields.\n",
    "\n",
    "* **examples**: Holds the items of the dataset. Each item is a list of values.\n",
    "\n",
    "* **attrs**: The indexes of the features (by default in the range of [0,f), where *f* is the number of features). For example, `item[i]` returns the feature at index *i* of *item*.\n",
    "\n",
    "* **attr_names**: An optional list with attribute names. For example, `item[s]`, where *s* is a feature name, returns the feature of name *s* in *item*.\n",
    "\n",
    "* **target**: The attribute a learning algorithm will try to predict. By default the last attribute.\n",
    "\n",
    "* **inputs**: This is the list of attributes without the target.\n",
    "\n",
    "* **values**: A list of lists which holds the set of possible values for the corresponding attribute/feature. If initially `None`, it gets computed (by the function `setproblem`) from the examples.\n",
    "* **distance**: A function from a pair of examples to a non-negative number.Should be symmetric, etc. Defaults to mean_boolean_error since that can handle any field types.\n",
    "\n",
    "* **name**: Name of the dataset.\n",
    "\n",
    "Its constructor is `Dataset( name=' ', target=' ', attr_names =' ' )`.\n",
    "\n",
    "Normally, we only need to call the constructor to create a dataset object. After we have a dataset object d, we can then access it's attributes/fields using d.field_name, such as d.examples and d.target and d.inputs.\n",
    "\n",
    "In this demo, we call the constructor of the DataSet class to create a dataset object from the input data file which should be stored in the directory of 'aima-data'. The name = `marks`,which is the name of datafile, target = `Pass`, attr_names = `Mid-Sem-Mark Pass`, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "marks = DataSet(name='marks',target='Pass', attr_names='Mid-Sem-Mark Pass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Prepare for the training data set and the test data set\n",
    "The training data set is represented by [train_data, train_label] while the test data set is represented by [test_data, test label], where train_data, train_label, test_data, and test label are lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =[]\n",
    "train_label = []\n",
    "test_data = []\n",
    "test_label = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `seperate_train_and_test_data(dataset.examples, number of test data)` can be used to generate select some data samples randomly from the input dataset as test data set. The rest of the input dataset will be the training data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_label, test_data, test_label = seperate_train_and_test_data(marks.examples, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take two samples from the test set as the future data samples, called futureSample.\n",
    "\n",
    "\n",
    "To test student score with specific number, we can put it in futureSample_data:\n",
    "\n",
    "    *Replacing:\n",
    "        `futureSample_data = test_data[-2:]`.\n",
    "        \n",
    "    *To: \n",
    "        `futureSample_data = [[A],[B],[C],...]`\n",
    "A,B,C is the student score\n",
    "Result can be seen in Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32.72283304]\n",
      " [64.03932042]]\n"
     ]
    }
   ],
   "source": [
    "futureSample_data = []\n",
    "futureSample_label = []\n",
    "futureSample_data = test_data[-2:]\n",
    "futureSampe_label = test_label[-2:]\n",
    "\n",
    "test_data = test_data[:-2]\n",
    "test_label = test_label[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Train a decison tree learner\n",
    "Define a decison tree learner based on entropy criterion using `DecisionTreeClassifier()`and train it using the train data set. Reference the following site for more information about this method: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTL = DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train DTL classifier using the training data set (train_data, train_label). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTL.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Test DTL classifier's performance using test data set\n",
    "Use the method predict() in the classifier to calculate the predicted values of test samples and then use the method test_accuracy() to calculate  the average accuracy as the holdout validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = DTL.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.63636363636363%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy(solution, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Predict the class for the data samples in the future sample set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70] [1]\n",
      "[42.07545454] [1]\n"
     ]
    }
   ],
   "source": [
    "for x in futureSample_data:\n",
    "    print(x,DTL.predict([x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
